## Virtual/ization
By Luke Daccord

### Introduction
The relationship between the philosophical concept of the virtual and the technological phenomena of virtualization will be the topic of this entry. While most have probably not heard of the former, anyone who has used a computer in the last 50 years has experience with the latter — whether they know it or not. Guided by Brian Massumi’s writing on the Deleuzian concept of the virtual in _Parables for the Virtual_, and Tung-Hui Hu’s history of virtualization technology in _Prehistory of the Cloud_, I will attempt to put these two ideas into conversation. Questions of the relationship between the philosophical and technological virtual are at the fore of contemporary media studies, and the topic certainly comes with many challenges, as we shall see. I by no means pretend to succeed in their synthesis here but rather aim to map a potential outline of the discourse, looking to generate new and ideas and questions while also being candid about the struggles of the comparison. We will begin first with an exploration of the philosophical concept of the virtual as it is presented by Massumi, and then proceed to look at Hu’s history of virtualization technology while keeping an eye open for similarities and collisions between the two. Finally, in a closing section I confront the question of their relationship directly, suggesting two central ways in which we can analyze the virtual and virtualization in combination.

### Image Reception: Intensity/Content
In his chapter titled “The Autonomy of Affect” from _Parables for the Virtual_, Massumi begins his introduction to the virtual by looking at the mechanics of image reception. Drawing from empirical research into cognition, he argues that the _intensity_ of an image (the strength or duration of it’s effect) is not logically connected to its _content_ in any straightforward way (Massumi, 24). Instead, image reception appears to be multi-level, the experience being immediately bifurcated into these two systems of, again, _intensity_ and _content_. While the content of an image is its indexing to conventional and recognized meaning and context, or its “sociolinguistic qualification,” intensity is not something that can be qualified semantically or semiotically. It is a different type of force, and also functions in a distinct way physiologically: Massumi connects intensity to unconscious reactions which can be tracked on the surface of the body with measurements like conductivity of the skin, whereas qualified content on the other hand belongs more to “depth reactions” like heart rate and breathing (25). These qualified depth reactions are also unconscious, but stem from things like expectation, which is to say, self-consciously placing oneself within a narrative. This latter claim of conscious understandings effecting unconscious bodily reactions (and vice versa) is fairly intuitive and unremarkable — but what is new is this diagram that Massumi puts forth is the dimension of intensity which seems to have a direct line to the unconscious reactions of the body, existing outside of any sort of expectation, linear narrative, or meaning in general. This intensity is non-linear, and Massumi also describes it as something not passive yet also not active. “A state of suspense, potentially disruption,” which is filled with “vibratory motion” (26). Massumi thinks an understanding of this intensity is radically lacking in contemporary cultural theory. He holds that in order to understand the new, the emerging, and the unexpected, we must escape the “explanatory heaven” of semiotic analysis, “the place where nothing ever happens” (27). We must not look simply at the “image,” but instead the entirety of what he terms the “expression-event” — encompassing not only conscious interpretations of symbols, contexts, storylines and so forth, but also this non-representational intensity that operates within each experience.

### The Virtual
Massumi begins his second section of the chapter looking at another scientific study, and for this I will go into some brief detail: Volunteers were asked to asked to flex a finger at the moment of their choosing, while also signalling the moment of their decision to do so. Their brain waves were monitored, and what was discovered is that 0.3 seconds previous to the volunteer consciously recording their decision, there was a massive spike in brain activity. Asked to speculate on the implications this may have for free will, one of the researchers suggested that “we may exert free will not by initiating intentions but by vetoing, acceding or otherwise responding to them after they arise” (Massumi, 29). From this we get the idea that will and consciousness may in fact be _subtractive_, reducing a complexity too rich to be functionally expressed. This time 0.3 seconds before the decision is overfull, “in-excess of the actually performed action” Massumi says (29). It is in fact a moment of the same intensity just explored. Massumi describes it as full of “incipient action” — action about to happen and barely contained (30). This intensity is a mass of actions and expressions each on the verge of actualization, threatening to occur, of which only one can be selected to be actualized. This dimension is the virtual. “The body is as immediately virtual as it is actual” Massumi tell us (30). The activity and expressivity of the body cannot be explained solely by the physically existing, for it is constituted as much by this abstract virtuality is as it is by its “concrete-ness.” Thus, this virtual may not be physical but it is certainly real. The term “unactualized” is then the more appropriate one to describe these potentials then, as opposed to “unrealized.”

### Applying the Virtual
These ideas of the virtual and of intensity may seem too conceptually abstract to employ as of yet, but Massumi offers a fascinating application looking at the mannerisms of Ronald Regan that should give some direction. He sees the jerkiness of Regan’s movement and the ambiguity of his speech to have had the effect of emitting vast arrays of virtualities. Physically, he was able to compress into a single movement “potential moments that are in some way made present without being actualized” (Massumi, 41). Verbally, the content of his speech was so imprecise that it could be actualized as different claims by its various receiving apparatus like the family, the church, the school, and so on. Regan simply generated intensity, and content could be constructed on the receiving end. This allowed him to represent may different things to many different groups of people (its interesting to note how incredibly similar analyses have since popped up decades later in trying to understand the election of Donald Trump). Massumi also gives us a great question to begin to considering the virtual in line with technology: “What is of dire interest now, post-Regan” he says, “is the extent to which he contracted into his persons operations that might be argued to be endemic to late-capitalist, image- and information-based economies” (42). He reflects on the rapid switching, interruptions, and juxtapositions of television, advertising and the internet. “Everywhere the cut, the suspense — incipience. Virtuality, perhaps?” (42). With this in mind, we now cut ourselves to Tung-Hui Hu’s history of virtualization, a pervasive technology which he demonstrates is also at the very base of this economy to which Massumi refers.

### Batch Processing to Time-Sharing 
Virtualization describes a technology through which things like data storage, applications, or operating systems can be abstracted away from their underlying hardware or software. Common consumer-end examples of contemporary virtualization technology that most would be familiar with includes things like cloud storage, virtual private networks (VPNs), and operating system emulators, while business uses for virtualization technology might also include services like cloud computing and server virtualization, among others. In _A Prehistory of the Cloud_, Hu demonstrates how the abstraction provided by virtualization technology should be thought of as neither a new phenomena nor a benign one. The contemporary cloud in fact has longstanding ideological roots traceable back all the way to the early days of computing. As Hu shows, virtualization mediates each interaction and relation we have with and through computers, which is to say, just about everything.

The direct predecessor of modern-day virtualization technology is what was know as “time-sharing,” itself an innovation of the original “batch processing” methods of early computing. Using the batch processing computer, programmers would submit punch cards or magnetic tape to a human operator who would then run these programs through the computer one at a time. It could take hours, or even days to receive back one’s results. First put to use at MIT in the early 1960’s, what time-sharing made possible on the technological level was a rapid division of the computer’s time between multiple programs. “By spending a fraction of a second on one user’s program, switching rapidly to other user’s programs, then immediately moving back to the first program, it appeared as if the computer were responding instantly to each user’s commands” Hu writes (38-39). This technology meant that multiple programmers could all be using to the same quarter-million dollar computer simultaneously and _feel_ as though it were their own, it was the beginnings of some sort of [[intimacy|Intimacy]]. A dozen abstract computers seemed to spring from what in actuality was one physical machine, one piece of hardware. Although not quite yet the seamless and pervasive cloud technology we know today, the shift to time-sharing computers was the first step towards modern day virtualization technology. We can hopefully already begin to see some similarities to the virtual here: Both the virtual and the virtualized time-sharing computer sit in a sort of funny position in terms of their “realness” in relation to the subject. As abstract layers of reality, their physical existence doesn’t seem to quite match up with our experience of it, yet both are real. This abstraction of virtualization technology will only increase as we go along.

The new and more diffuse method of time-shared computing brought with it new ways of managing those using it. In order to track each programmer’s individual usage of the computer, a completely novel idea at the time was put into place: naming the user. In time-sharing we see the first see this model of the user with a username and password, and also the first developments of some sense of “personal” computing — of being known or recognized by the computer. Virtualization is central in the creation of the modern day subject position of the [[user|User]] — a complex topic which should be explored in its own right.

### Virtualization as Isolation
With this new technology also came new threats. Just like in sharing the physical space of a city, sharing the physical space of the computer in a time-sharing system presents the problem of waste, and the risk of “contamination, uncleanliness, or infection” (Hu, 57). Programming errors on a time-sharing computer now threatened to disrupt all of its simultaneous users. One of the first solutions developed to combat this was an automatic routine termed the system monitor, supervisor, or executive — a sort of barrier between programs and consequently users which made sure they didn’t overwrite or interfere with each other (59). “Garbage collection” was another method: A program which automatically removed “dead objects” (memory that is no longer in use) to prevent interference (59). Ideally, the garbage collector would run occasionally behind the scenes without even being noticed, allowing programmers to code without worry of the garbage being left behind. For Hu, the indiscreet garbage collector, in comparison to the direct action of the system monitor, “represents a shift from punishment to barely detectible methods of [[modifying behaviour|Population]]” (60).

These isolationist systems created by virtualization technology which separated users would eventually become the default methods for ensuring the privacy and “health” of the users on the cloud. Virtualization constructs for the user a simulated environment which they feel they have absolute control over, while simultaneously restricting that user’s data from interfering with another’s. The very same feeling of intimacy fostered by time-sharing technology persists today as the cloud, but even with even more layers of abstraction: Instead of a single machine serving a building of programmers, Amazon’s Elastic Computer Cloud, for example, is comprised of thousands of different machines scattered across the globe. These machines can distribute loads for various tasks amongst these themselves, as if one massive amorphous being from which springs thousands of these illusionary, seemingly-intimate “virtual machines” for its clients. Similarly, thousands of the “virtual drives” of cloud storage might share the same physical space, or one virtual drive might span thousands of physical spaces. Virtual private networks also conjure one’s own “private channel inside the public internet” (Hu, 62). Crucially, in all this the presence of both other users and of the technology enabling this isolation in the first place is rendered nearly invisible in the process. Hu describes virtualization as “the culmination of the process of making control less and less explicit and less intrusive” (62). Instead of looking at the cloud as the isolated environment as presents itself to us, Hu encourages us to become aware of its physical constitution and the circumstances which gave birth to and still control the technology.

### Virtualization as Enabling the Virtual
So far I’ve only hinted at potential points of comparison between the two virtuals, but lets now try to tackle them directly. I envision two approaches, the first looks for ways in which the technologies of virtualization operationalize the virtual, and enable a saturating of experience and interaction with the incipience and intensity that Massumi sees as endemic to the late-capitalist and image-based economy. One example of this might be something like Facebook’s “Like” or similar derivates (the upvote, potentially the “favourite”). I suggest that the Like, in certain ways, functions similarly to Regan in Massumi’s analysis in that its semantic ambiguity generates intensity and the multiple possible actualizations of meaning that come with the virtual. The Like is a remarkably hollow interaction, arguably even borderlining on a phatic one — simply an acknowledgement of interaction itself. The _content_ is stripped away and what remains, or perhaps we could say is manufactured, is rather _intensity_. Unlike a written comment on a post, the ambiguity of the Like is massively potentializing — it collects any variety of actual feelings and abstracts them, allowing them to be reimbued with meaning on the receiving end by the poster or simply experienced as attention in general, just as Regan’s speech was experienced as confidence in general. Virtualization technology is critical to this because it is what enables the isolation of the user, and not just their reconnection within the [[network|Networks]], but the terms by which they are reconnected.

Admittedly, it’s hard not to fall into a “vulgar” reading of the virtual with this sort of analysis, assigning it to any and everything that seems to relate to some form of potential on the internet (“Suggested Friends”? “Other Videos You Might Find Interesting”?) and then simply insisting on virtualization technology’s central role in the formation of the net, the user, and computers in general (at a certain point everything to do with computers appears like virtualization). Even less productive in this setting would be to fall into the colloquial uses of the term virtual: virtual reality, virtual economies, etc. (although productive inquiries into this sense of the virtual can certainly be found [[elsewhere|]]). Nonetheless, virtualization technology is undoubtably what allows for an incredible amount of control over the terms of our interactions and the form of our experience online, and understanding how it can be used to operationalize the virtual is an important process to consider.

### Virtualization as The Virtual
The second way I suggest we can imagine the virtual in direct relation to virtualization is looking for ways in which the functioning of virtualization technology appears to mimic the virtual itself — not virtualization operationalizing the virtual, but virtualization technology assuming the form of the virtual. Amazon’s “Mechanical Turk” is perhaps the best example. It describes itself on its website as a service which “gives businesses access to a diverse, on-demand, scalable workforce and gives Workers a selection of thousands of tasks to complete whenever it's convenient.” Workers complete tasks that are just slightly more complex than could be achieved by a computer, like identifying photos or videos or transcribing audio recordings, for payoffs of a few cents per task. This workforce of users is structured remarkably similarly to Massumi’s description of the virtual, and operates just like Amazon’s Electronic Computer Cloud. It organizes disparate groups of workers all over the globe in an amorphous mass of virtualized labour potential, which can be actualized at a moments notice to complete a task. Operating similarly might also be something like Uber, which amasses the otherwise isolated vehicles of others into another virtualized and virtual realm of potential. When a ride is called with the press of a button, all but one of these roving virtualities will then be actualized and then put to work. In this case we might also make connections to the previous discussion on the Facebook Like, in that Uber also feeds these feelings of intensity and incipience to the consumer.

As we increase in layers of technological abstraction do we allow for the exposing of more surfaces of the virtual? Can virtualization technology protocolize the virtual itself? Is virtualization to computer hardware as the virtual is to the expression-event? I've tried to approach these sorts of questions here but by no means can offer any concrete answers. As Massumi and Hu both show, the virtual and virtualization technology are powerful concepts which resist critique in their near invisible operation, thus allowing them to function as premier methods of control. Just in the same way that Massumi tells us not to forget that the physical is also virtual, Hu tells us not to forget that the virtualized is also physical. Their positions seem to want to approach each other naturally, however there is undoubtably still much work to be done in their final synthesis.

## Works Cited

Hu, Tung-Hui. _A Prehistory of the Cloud_. Cambridge, MA: The MIT Press, 2016.
Massumi, Brian. Parables for the Virtual. Durham, NC: Duke U Press, 2002.

